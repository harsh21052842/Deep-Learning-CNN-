{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNz0V7MVpKTx8OsGq2VvfQN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oJGuWTxtFP79"},"outputs":[],"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","source":["##Data Preprocessing"],"metadata":{"id":"OuGSrVdaMukD"}},{"cell_type":"code","source":["# Training set data preprocessing\n","\n","#ImageDataGenerator performs the operations\n","train_datagen = ImageDataGenerator(\n","    rescale = 1./255, #Feature Scaleing\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True  #Flipping and storing the identification for inverted image detevction \n","    #Prevent Over Feeding\n",")\n","\n","#Connects Image Directory to ImageDataGEnerator tool\n","training_set = train_datagen.flow_from_directory(\n","    'dataset/training_set',# Specifies the directory path\n","    target_size=(64,64),   # All images are resized to 64x64\n","    batch_size=32,         # No. of samples per batch \n","    class_mode='binary'    #Only two outputs Cat and Dog so binary\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"A-LtZ-FLMro2","executionInfo":{"status":"error","timestamp":1685292103302,"user_tz":-330,"elapsed":718,"user":{"displayName":"Kumar Harsh","userId":"07034143436983670483"}},"outputId":"d6c405ac-b7da-40bb-ffda-1bf581fd4303"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-5d460f41b338>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Connects Image Directory to ImageDataGEnerator tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m training_set = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m'dataset/training_set'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-> 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/training_set'"]}]},{"cell_type":"code","source":["#Test Set Preprocessing\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory(\n","    'dataset/test_set',# Specifies the directory path\n","    target_size=(64,64),   # All images are resized to 64x64\n","    batch_size=32,         # No. of samples per batch \n","    class_mode='binary'    #Only two outputs Cat and Dog so binary\n",")"],"metadata":{"id":"bbYamK0hNsu2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnn = tf.keras.models.Sequential()"],"metadata":{"id":"gJKYsrGafdwL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convolution : Finding features through feature scale adding the features and storing them into a \n","#               new matrix for makinng image smaller and keeping all the features also at the same time. \n","\n","## Conv2D a layer used for image\n","\n","## filters=32: The filters parameter specifies the number of filters (also referred to as channels) \n","# in the convolutional layer. In this case, we have set it to 32, which means the layer will learn 32 different filters.\n","\n","## kernel_size=3: The kernel_size parameter defines the size of the convolutional kernel. It specifies the height and\n","# width of the filter that will slide over the input image. Here, we have set it to 3, indicating a 3x3 filter.\n","\n","\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3,activation='relu',input_shape=[64,64,3]))"],"metadata":{"id":"KigMjCtkfmzm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Pooling\n","\n","# pool_size : Size of matrix by which pooling is done.\n","# strides : Step-size of the matrix.\n","# MaxPool2D : Polling for 2d images\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"],"metadata":{"id":"icDrxtHOjQAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3,activation='relu',input_shape=[64,64,3]))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"],"metadata":{"id":"UHLZ7t1nhzh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Flattening : Converting 2D array into 1D array for ANN use\n","\n","cnn.add(tf.keras.layers.Flatten())"],"metadata":{"id":"e9cV28iDh-EP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Full Connection : Connecting the flattened layer to ANN\n","\n","cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu' ))"],"metadata":{"id":"nDZ2mcgHjbnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid' ))"],"metadata":{"id":"3OD0n-EzlkuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compiler : \n","\n","cnn.compile(optimizer='adam' , loss = 'binary_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"lqcIfKY0mD2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnn.fit(x = training_set, validation_data = test_set , epochs = 25)"],"metadata":{"id":"lsPFJqu-mtDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from keras.preprocessing import image\n","\n","# Loading the image\n","test_image =  image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = ( 64 , 64 )) # target_size should be equal to the target size when training \n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0 )# Adding fake dimension to match the dimnsions of training set\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result [0][0] > 0.5:\n","  prediction = 'dog'\n","else\n","  prediction = 'cat'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"FQWUwsRHTiYY","executionInfo":{"status":"error","timestamp":1685344334474,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kumar Harsh","userId":"07034143436983670483"}},"outputId":"b62c4f56-d148-4b11-ac95-daaf1d0ae14e"},"execution_count":2,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5fff4d995a87>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Loading the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/single_prediction/cat_or_dog_1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# target_size should be equal to the target size when training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;31m# Adding fake dimension to match the dimnsions of training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"]}]},{"cell_type":"code","source":["print(prediction)"],"metadata":{"id":"WaqvNLgFWayL"},"execution_count":null,"outputs":[]}]}